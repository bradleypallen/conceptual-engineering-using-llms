[{"hyp": "A district of Kowloon, China.", "ref": "tgt", "src": "The City <define> Chiuchow </define> is Kowloon 's other top restaurant and is famous for its goose dishes and other specialties from the Chiuchow region ( you may also wish to try the beef satay done in a creamy sauce ) .", "tgt": "The Chaoshan region where the Teochew dialect is spoken.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is \"Chiuchow,\" which the target correctly identifies as the Chaoshan region where the Teochew dialect is spoken. However, the output incorrectly defines \"Chiuchow\" as a district of Kowloon, China. The input does not provide any information to suggest that \"Chiuchow\" is a district of Kowloon. Instead, it mentions that the restaurant named \"The City Chiuchow\" is located in Kowloon and is famous for its dishes from the Chiuchow region. Therefore, the output is incorrect and is a hallucination.", "predicted": "Hallucination"}, {"hyp": "(Wicca) A witchdoctor.", "ref": "tgt", "src": "\u201c I went to see the witchdoctor , the <define> igqira </define> . And he spoke to the izinyanya , the spirits of the ancestors . \u201d", "tgt": "(South Africa) A traditional tribal diviner or spiritual healer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The term \"igqira\" is defined correctly in the target as a traditional tribal diviner or spiritual healer from South Africa. However, the language model incorrectly defines it as a witchdoctor in the context of Wicca. This is incorrect because the term \"igqira\" is specific to South African culture and does not have any known associations with Wicca. Therefore, the output is a hallucination as it contains information that cannot be reasonably inferred from the input.", "predicted": "Hallucination"}, {"hyp": "(nautical) A halyard.", "ref": "tgt", "src": "Haul away , keeping strain on both parts of the halyard so that the <define> pigstick </define> remains vertical as it goes up and does n't foul the spreaders .", "tgt": "(nautical) A staff that carries a flag or pennant above the mast of a sailboat.", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The term to be defined in the input is 'pigstick', but the output provides a definition for 'halyard'. The target definition confirms that a 'pigstick' is a staff that carries a flag or pennant above the mast of a sailboat, not a halyard. Therefore, the output is incorrect and does not accurately define the term given in the input.", "predicted": "Hallucination"}, {"hyp": "The quality of being rational.", "ref": "tgt", "src": "And what difference is there between the credibleness and <define> rationalness </define> of any of these wonders and the credibleness and rationalness of Papal infallibility ?", "tgt": "(archaic) The quality or state of being rational.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined in the input is \"rationalness,\" and the language model correctly provides a definition that aligns with the target: \"The quality of being rational.\" This definition is accurate and can be reasonably inferred from the term itself. Therefore, the output is correct and not a hallucination.", "predicted": "Not Hallucination"}, {"hyp": "(uncountable) The study of trees.", "ref": "tgt", "src": "It is now generally supposed that the forbidden fruit was a kind of citrus , but certain facts connected with <define> arborolatry </define> seem to me to disprove this opinion .", "tgt": "The worship of trees.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term \"arborolatry\" is defined as the worship of trees, as correctly stated in the target. However, the language model incorrectly defines it as the study of trees. This is not accurate or correct, therefore it is a hallucination.", "predicted": "Hallucination"}, {"hyp": "(zoology) A pseudostome.", "ref": "tgt", "src": "The pseudembryo moves rapidly in the water , rolling round and swinging from side to side ; as a rule , and especially when at rest , the surface bearing the pseudostome and <define> pseudoproct </define> is turned downwards .", "tgt": "(biology) The anal opening on the pseudembryo of an echinoderm.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is 'pseudoproct', but the language model incorrectly defines 'pseudostome'. The correct definition, as given in the target, is that a pseudoproct is the anal opening on the pseudembryo of an echinoderm. The output does not match this definition, indicating that the language model has generated incorrect information.", "predicted": "Hallucination"}, {"hyp": "Resembling or characteristic of umber.", "ref": "tgt", "src": "<define> umbery </define> gold", "tgt": "Of or pertaining to umber; like umber.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"umbery\" is correctly defined as resembling or characteristic of umber, which aligns with the target definition of being of or pertaining to umber. The language model has accurately inferred the meaning from the input.", "predicted": "Not Hallucination"}, {"hyp": "(music, transitive) To play (a note) at the same time.", "ref": "tgt", "src": "Now the two bounding notes of an enharmonic tetrachord of the relevant sort will indeed both be the lowest notes of pykna when the tetrachords are put together in conjunction ; but the higher of them can never <define> abut on </define> a pyknon in the case envisaged here , where the tone is introduced to disjoin the tetrachords .", "tgt": "(transitive) To border on.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is \"abut on\", and the target definition is \"(transitive) To border on.\" However, the output provided by the language model is \"(music, transitive) To play (a note) at the same time.\" This definition is not accurate as it does not align with the target definition and does not correctly interpret the term \"abut on\" in the context of the input sentence. The term \"abut on\" in the context of the sentence refers to one note bordering or being adjacent to another, not being played at the same time.", "predicted": "Hallucination"}, {"hyp": "(Australia, New Zealand, colloquial) A hatfish.", "ref": "tgt", "src": "Noah did n't realize when he stayed on the job - he was then about 600 years old and built the ark and drove the animals in two by two , the <define> hatfish </define> and the kangaroo \u2014 \u2014 he did n't realize he was laying the foundation for an occupation for old men in New York , several years later .", "tgt": "(colloquial) Synonym of halibut", "model": "", "task": "DM", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The target definition indicates that \"hatfish\" is a colloquial synonym for halibut. However, the output generated by the language model incorrectly defines \"hatfish\" as a term used in Australia and New Zealand, without providing any specific meaning. The output does not match the target and does not provide a correct or accurate definition based on the given input.", "predicted": "Hallucination"}, {"hyp": "Having a keen sense of humor.", "ref": "tgt", "src": "<define> keen </define> satire or sarcasm", "tgt": "Acrimonious, bitter, piercing.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input term to be defined is \"keen satire or sarcasm\", which refers to sharp, biting, or incisive humor. The target definition provided is \"acrimonious, bitter, piercing\", which aligns with the input term. However, the output provided by the language model, \"having a keen sense of humor\", is not an accurate definition of the input term. It is too broad and does not capture the specific qualities of bitterness and piercing wit that characterize keen satire or sarcasm. Therefore, the output is incorrect and off point.", "predicted": "Hallucination"}, {"hyp": "A person who has a pass.", "ref": "tgt", "src": "<define> Passholders </define> can visit the theme park all year round .", "tgt": "One who holds a pass.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined in the input is \"Passholders\", and the language model correctly generates a definition that aligns with the target, \"A person who has a pass.\" This definition is accurate and can be reasonably inferred from the input.", "predicted": "Not Hallucination"}, {"hyp": "(colloquial) A term of endearment.", "ref": "tgt", "src": "Hey , <define> babe </define> , how 's about you and me getting together ?", "tgt": "(affectionate) Darling (term of endearment).", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"babe\" is indeed often used as a colloquial term of endearment. While the output does not match the target exactly, it still provides a correct and accurate definition of the term in question.", "predicted": "Not Hallucination"}, {"hyp": "(intransitive) To speak in a slurred manner.", "ref": "tgt", "src": "Sometimes life takes hold of one , carries the body along , accomplishes one 's history , and yet is not real , but leaves oneself as it were <define> slurred over </define> .", "tgt": "(dated) To deal with something hurriedly; to treat in a perfunctory manner.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined in the input is \"slurred over\", but the output provides a definition for \"to speak in a slurred manner\", which is not the same. The target definition indicates that \"slurred over\" means to deal with something hurriedly or in a perfunctory manner, which is not reflected in the output. Therefore, the output is incorrect and off point.", "predicted": "Hallucination"}, {"hyp": "A device that simulates walking.", "ref": "tgt", "src": "During the late 1960s and early 1970s , it was also the site of the lunar 1\u20446 gravity <define> walking simulator </define> rig .", "tgt": "Used other than figuratively or idiomatically: see walking,\u200e simulator.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The term to be defined is \"walking simulator rig\", specifically one used under lunar 1\u20446 gravity conditions. The output definition, \"A device that simulates walking\", is too broad and does not capture the specific context of the term as used in the input. The definition should include information about the simulation of walking under lunar gravity conditions.", "predicted": "Hallucination"}, {"hyp": "(intransitive, colloquial) To be very hot.", "ref": "tgt", "src": "Let 's face it , they 're there for a good stroll on a Sunday afternoon when it 's <define> pissing </define>   outside .", "tgt": "(ambitransitive, mildly, _, vulgar) To rain heavily.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is 'pissing', used in the context of describing weather conditions. The target definition correctly identifies it as a colloquial term for heavy rain. However, the output from the language model inaccurately defines it as being very hot. This is not correct in the given context and cannot be inferred from the input, making it a hallucination.", "predicted": "Hallucination"}, {"hyp": "(geology) Synonym of synecdoche", "ref": "tgt", "src": "In the Ronne <define> syneclise </define> the thickness of sedimentary cover reaches 13.5 km and the folded basement has a complex relief owing to block movements along faults of different rank .", "tgt": "(geology) A large, shallow depression formed on a continental platform due to slow subsidence.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'syneclise' is incorrectly defined as a synonym of 'synecdoche', which is a figure of speech in literature. The correct definition, as provided in the target, is a geological term referring to a large, shallow depression formed on a continental platform due to slow subsidence. The output does not match the target and is not accurate based on the given input.", "predicted": "Hallucination"}, {"hyp": "(informal) A person who is addicted to sport.", "ref": "tgt", "src": "I have spent much of my life a recovering <define> sportaholic </define> . If it bounced , rolled , slid , or flew , I chased it . Or watched it .", "tgt": "A sportsaholic.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"sportaholic\" is defined accurately as a person who is addicted to sports. This definition aligns with the context provided in the input, where the speaker mentions chasing or watching anything that bounced, rolled, slid, or flew, indicating a strong interest or obsession with sports. Therefore, the language model's output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "Resembling or characteristic of French surrealism.", "ref": "tgt", "src": "Quatermass also mediated Wellsian influence on the tone and preoccupations of the new hybrid SF \u2013 horror - film genre , with its monstrous <define> Gigeresque </define> fusions of machine and organism [ \u2026 ]", "tgt": "Reminiscent of H. R. Giger (born 1940), Swiss surrealist painter best known for nightmarish biomechanical imagery.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The term 'Gigeresque' is defined in the target as being reminiscent of H. R. Giger, a Swiss surrealist painter known for his biomechanical imagery. However, the output incorrectly defines 'Gigeresque' as being characteristic of French surrealism. This is incorrect as H. R. Giger was Swiss, not French, and his work is specifically known for its biomechanical nature, not just general surrealism. Therefore, the output is not accurate or correct.", "predicted": "Hallucination"}, {"hyp": "The state or quality of being a princess.", "ref": "tgt", "src": "\u201c What are you doing ? \u201d Carly asked , looking around . \u201c You do n\u2019t want to be in here . You \u2019re way too much of a princess . \u201d / \u201c Remember how I grew up , Carly . I \u2019ve earned my <define> princessness </define> . \u201d", "tgt": "The quality of being a princess.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined in the input is 'princessness', and the language model correctly generates a definition that aligns with the target: \"The quality of being a princess.\" The output, \"The state or quality of being a princess,\" is essentially the same as the target, just using slightly different wording. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "(Australia, New Zealand, colloquial) A tree.", "ref": "tgt", "src": "He climbed over the sedge and eely oarweeds and sat on a stool of rock , resting his ashplant in a <define> grike </define> .", "tgt": "(chiefly, British) A deep cleft formed in limestone surfaces due to water erosion; providing a unique habitat for plants.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'grike' is defined in the target as a deep cleft formed in limestone surfaces due to water erosion, which is a geological feature. However, the output provided by the language model defines 'grike' as a tree, which is a biological entity and not related to the correct definition. Therefore, the output is incorrect and not accurate.", "predicted": "Hallucination"}, {"hyp": "(intransitive) To die.", "ref": "tgt", "src": "\" But why should I be in another room ? \" \" You <define> passed over </define> in the night . \" \" Passed over ? Do you mean I died ? \" \" Yes , lady , you died . \" There was a long silence .", "tgt": "(intransitive, euphemistic) To die and thus progress to the afterlife.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined in the input is \"passed over,\" and the context makes it clear that this term is being used to mean \"to die.\" The output generated by the language model accurately reflects this definition. While the target definition includes the additional detail of progressing to the afterlife, this is not explicitly stated in the input, so the language model's simpler definition is still correct and accurate based on the information provided.", "predicted": "Not Hallucination"}, {"hyp": "Alternative form of scatter site", "ref": "tgt", "src": "It is designed for single - family use in subdivisions or <define> scatter sites </define> and available as a standardized product   [ \u2026 ]", "tgt": "An area of state-sponsored housing used as a shelter for homeless people; such housing is scattered across different parts of a city rather than concentrated in one place.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The output provided by the language model is not accurate or detailed enough. It simply states that the term is an \"alternative form of scatter site\" without providing any definition. The target definition, on the other hand, provides a detailed explanation of what \"scatter sites\" are, stating that they are areas of state-sponsored housing scattered across different parts of a city. The language model's output does not match this definition, making it a hallucination.", "predicted": "Hallucination"}, {"hyp": "The state or condition of being obsolescent.", "ref": "tgt", "src": "One way is to legislate extended warranties on products , so washing machines and refrigerators last for 30 years instead of 10 . Another is to ban planned <define> obsolescence </define> , so manufacturers ca n\u2019t create products that are designed to fail .", "tgt": "(uncountable) The state of being obsolete\u2014no longer in use; gone into disuse; disused or neglected.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined in the input is 'obsolescence'. The output provided by the language model, 'The state or condition of being obsolescent', is a correct and accurate definition of 'obsolescence'. Although the output definition does not exactly match the target definition, it still accurately defines the term in a way that can be reasonably inferred from the input. Therefore, the output is not a hallucination.", "predicted": "Not Hallucination"}, {"hyp": "Alternative form of gartel (\u201cdance\u201d)", "ref": "tgt", "src": "The bride stands perfectly still at one end of the room and holds a long <define> gartel </define> while the male dancing before her holds the other end .", "tgt": "(Judaism) A belt or sash used in prayer.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'gartel' is defined in the target as a belt or sash used in prayer in Judaism. However, the output generated by the language model incorrectly defines 'gartel' as an alternative form of dance. This definition is not accurate or relevant to the context provided in the input, making it a hallucination.", "predicted": "Hallucination"}, {"hyp": "Capable of being endured.", "ref": "tgt", "src": "Misery colored by the greens and blues in my mother 's voice took all of the grief out of the words and left me with a conviction that pain was not only <define> endurable </define> , it was sweet .", "tgt": "Able to be endured; tolerable; bearable.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined in the input is \"endurable\", and the language model correctly generates a definition that aligns with the target: \"Able to be endured; tolerable; bearable.\" The output \"Capable of being endured\" is a correct and accurate definition of \"endurable\", therefore, it is not a hallucination.", "predicted": "Not Hallucination"}, {"hyp": "(geology) Of or pertaining to the Alps.", "ref": "tgt", "src": "In 1884 O. Heer published a comprehensive account of the <define> nival </define> flora of   Switzerland , in which he listed 338 species of flowering plants found above 2600   m. ; of these , 6 were found above 3900 m.", "tgt": "(botany) Found or thriving in snowy conditions.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'nival' is supposed to be defined in the context of botany, referring to plants found or thriving in snowy conditions. However, the output provided by the language model incorrectly defines 'nival' in the context of geology, pertaining to the Alps. This is not accurate or relevant to the given input.", "predicted": "Hallucination"}, {"hyp": "Capable of being parachuted.", "ref": "tgt", "src": "<define> parachutable </define> supplies", "tgt": "Capable of being deployed by parachute.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"parachutable\" indeed refers to something that is capable of being parachuted or deployed by a parachute. Therefore, the language model's output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "In a muffled manner.", "ref": "tgt", "src": "A voice came <define> muffledly </define> from inside the closet .", "tgt": "In a muffled manner; indistinctly.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term to be defined is \"muffledly\", and the output correctly defines it as \"in a muffled manner\". Although the output is slightly less detailed than the target, it still accurately captures the essence of the term's meaning.", "predicted": "Not Hallucination"}, {"hyp": "(transitive) To cook (something) in a frying pan.", "ref": "tgt", "src": "Innawong et al . ( 2006 ) conducted experiments to study the effect of using nitrogen gas on the quality of <define> fried </define> chicken nuggets during pressure frying in terms of moisture retention and reduction in fat   [ \u2026 ]", "tgt": "Cooked in a deep fryer or pressure fryer or the like after being coated (breaded) in batter; compare deep-fried.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output definition does not match the target exactly, it is still a correct and accurate definition of the term \"fried\". The output defines \"fried\" as cooking something in a frying pan, which is a common method of frying. The target definition is more specific to the context of the input, referring to deep frying or pressure frying, but the output definition is not incorrect or off point. Therefore, the output is not a hallucination.", "predicted": "Not Hallucination"}, {"hyp": "A sleeveless garment worn at night.", "ref": "tgt", "src": "Winston wore a <define> nightcap </define> to stave off the cold .", "tgt": "A warm cloth cap worn while sleeping, often with pajamas, being common attire in northern Europe before effective home heating became widespread. [From 14th c.]", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The term to be defined is 'nightcap', and the target definition correctly describes it as a warm cloth cap worn while sleeping. However, the output from the language model incorrectly defines 'nightcap' as a 'sleeveless garment worn at night', which is not accurate. Therefore, the output is incorrect and off point, making it a hallucination.", "predicted": "Hallucination"}, {"hyp": "(obsolete) Old; old-fashioned.", "ref": "tgt", "src": "And thou , our Mother , twice two centuries <define> young </define> ,", "tgt": "(Not) advanced in age; (far towards or) at a specified stage of existence or age.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is \"young\", and the target definition accurately describes it as not being advanced in age or being at a specified stage of existence or age. However, the output provided by the language model incorrectly defines \"young\" as \"old\" or \"old-fashioned\", which is the opposite of the actual meaning of the term. Therefore, the output is incorrect and off point.", "predicted": "Hallucination"}, {"hyp": "A county of Hotan, Sichuan, China.", "ref": "tgt", "src": "The \u201c living fossil \u201d , metasequoia , for example , was once distributed over large areas of Europe , Asia and the Americas from the Cretaceous to the Tertiary periods . Destroyed by glaciers , its natural distribution in China is today limited to Sichuan \u2019s <define> Shizhu </define> county , Hubei \u2019s Lichuan county and Hunan \u2019s Longshan county .", "tgt": "A county of Chongqing, China.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input text defines \"Shizhu\" as a county in Sichuan, China. However, the output incorrectly defines it as a county of Hotan, Sichuan, China. The target also confirms that Shizhu is a county of Chongqing, China. Therefore, the output is incorrect and does not accurately reflect the information provided in the input.", "predicted": "Hallucination"}, {"hyp": "A small flag.", "ref": "tgt", "src": "Given the present crisis and empty coffers , working meetings geared toward results are more appropriate for politicians than a program of touristy forays , throngs waving <define> flaglets </define> and bulletproof glass , the whole culminating in a neo - feudal state banquet .", "tgt": "A small flag.", "model": "", "task": "DM", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The term \"flaglets\" is correctly and accurately defined as \"a small flag\" by the language model. This definition is in line with the target, indicating that the model's output is correct.", "predicted": "Not Hallucination"}, {"hyp": "(zoology) Of or pertaining to a minotaur.", "ref": "tgt", "src": "Elytra <define> miniatous </define> , with a large somewhat triangular black spot on their disk ,   [ \u2026 ]", "tgt": "(formal) Orange-red, the colour of red lead.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term to be defined is \"miniatous\", and the target definition provided is \"Orange-red, the colour of red lead.\" However, the output definition provided by the language model is \"Of or pertaining to a minotaur,\" which is not only incorrect but also unrelated to the term \"miniatous\". The model seems to have confused \"miniatous\" with \"minotaur\", leading to an inaccurate and off-point definition.", "predicted": "Hallucination"}, {"hyp": "(chemistry) The degree to which a substance is hydrated.", "ref": "tgt", "src": "DuBois and coworkers carried out extensive studies of the thermodynamic <define> hydricity </define> of metal hydrides ( 3.2 ) ; in many cases the metal product resulting following hydride transfer will bind a CH3CN ligand ( not shown in 3.2 ) , so comparisons of hydricity will be solvent - dependent .", "tgt": "(chemistry) The tendency in a transition metal hydride for an H- ion to transfer to a substrate", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'hydricity' in the context of the input is related to the tendency of a transition metal hydride to transfer an H- ion to a substrate. However, the output provided by the language model incorrectly defines 'hydricity' as the degree to which a substance is hydrated. This is not accurate or relevant to the context provided in the input.", "predicted": "Hallucination"}, {"hyp": "(video games) The state or condition of being bisexual in a video game.", "ref": "tgt", "src": "It can be argued that explicit representations of bisexuality , pansexuality , and other multiple - gender - attracted people are erased from games that use ' <define> playersexuality </define> ' as a mechanic .", "tgt": "(video games) The state of an NPC being attracted to the player character, especially without regard to gender, race, etc.", "model": "", "task": "DM", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The term 'playersexuality' in the context of video games does not refer to the state or condition of being bisexual. Instead, it refers to the state of a non-player character (NPC) being attracted to the player character, regardless of the player character's gender, race, etc. The output definition provided by the language model is therefore incorrect and off point.", "predicted": "Hallucination"}, {"hyp": "That\u2019s not happening at the moment.", "ref": "either", "src": "That\u2019s not happening.", "tgt": "That isn\u2019t gonna happen.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The input statement is \"That\u2019s not happening,\" and the target paraphrase is \"That isn\u2019t gonna happen.\" Both of these statements express a definitive negation of an event or action. However, the output generated by the language model, \"That\u2019s not happening at the moment,\" introduces a temporal element that was not present or implied in the original input. This suggests that the event or action might happen in the future, which is a deviation from the original meaning. Therefore, the output can be considered a hallucination as it contains information that cannot be reasonably inferred from the input.", "predicted": "Hallucination"}, {"hyp": "I have a permit to carry it.", "ref": "either", "src": "I have a permit.", "tgt": "Uh, I\u2019m validated.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input statement \"I have a permit\" is vague and does not specify what the permit is for. The model's output \"I have a permit to carry it\" adds specific information that was not present or implied in the original input, namely that the permit is for carrying something. This is a hallucination as it introduces information that cannot be reasonably inferred from the input. The target paraphrase \"Uh, I\u2019m validated\" maintains the ambiguity of the original statement, which is the correct approach for this task.", "predicted": "Hallucination"}, {"hyp": "The process is easy.", "ref": "either", "src": "Easy, easy.", "tgt": "Watch it now.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output can be considered a hallucination. The input \"Easy, easy\" is a common phrase used to tell someone to slow down or be careful, as indicated by the target \"Watch it now.\" However, the output \"The process is easy\" is a completely different context, suggesting that a task or process is simple to complete. This output does not accurately paraphrase the input, nor does it align with the target, thus it can be considered a hallucination.", "predicted": "Hallucination"}, {"hyp": "A number between five and eight.", "ref": "either", "src": "A five, six, seven, eight.", "tgt": "And 5, 6, 7, 8.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Not Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output can be considered a hallucination. The input is a simple list of numbers from five to eight, and the target paraphrase maintains this list format. However, the output changes the format to a range, which is not a direct paraphrase of the input. Additionally, the output introduces ambiguity as it could be interpreted as any number between five and eight, not necessarily the discrete numbers 5, 6, 7, and 8. Therefore, the output is not a correct or accurate paraphrase of the input.", "predicted": "Hallucination"}, {"hyp": "That is a safer way to travel.", "ref": "either", "src": "A lot safer that way.", "tgt": "Because it\u2019s safer.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is not a hallucination. It accurately paraphrases the input, maintaining the same meaning. The input \"A lot safer that way\" is rephrased in the output as \"That is a safer way to travel.\" The output introduces the concept of \"travel,\" but it can be reasonably inferred from the context of safety and ways/methods, which often relate to travel or movement. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "You\u2019re not a good scam artist.", "ref": "either", "src": "You\u2019re a scam artist.", "tgt": "You are an imposter.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output can be considered a hallucination. The input statement is \"You're a scam artist,\" and the target paraphrase is \"You are an imposter.\" However, the output generated by the language model is \"You're not a good scam artist.\" This output introduces a negative evaluation (\"not good\") that is not present in the original input or the target. Therefore, it can be said that the model is hallucinating this additional information.", "predicted": "Hallucination"}, {"hyp": "When did you see him?", "ref": "either", "src": "When\u2019d you last see him?", "tgt": "When was the last time you saw him?", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. It accurately paraphrases the input, maintaining the same meaning. However, it does not match the target exactly. The target includes \"the last time\" which is not present in the output, but this does not make the output a hallucination as it still conveys the same overall meaning as the input.", "predicted": "Not Hallucination"}, {"hyp": "Let me leave.", "ref": "either", "src": "Let me out of here.", "tgt": "Someone let me out.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. It accurately paraphrases the input \"Let me out of here\" to \"Let me leave.\" Both sentences express the same desire to exit or be released from a location or situation. Although the output does not match the target exactly, it still correctly conveys the same meaning as the input.", "predicted": "Not Hallucination"}, {"hyp": "It is not impossible.", "ref": "either", "src": "Nothing is impossible.", "tgt": "There\u2019s nothing that can\u2019t be done.", "model": "tuner007/pegasus_paraphrase", "task": "PG", "labels": ["Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination. It accurately paraphrases the input \"Nothing is impossible\" by stating \"It is not impossible.\" Although the output does not match the target exactly, it still conveys the same meaning as the input, which is the goal of paraphrase generation. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "Tom decided to leave the company.", "ref": "either", "src": "Tom d\u00e9cida de quitter la soci\u00e9t\u00e9.", "tgt": "Tom has decided to leave the company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input sentence in French is correctly translated into English. The only difference between the target and the output is the tense of the verb \"decide\". In the target, it's \"has decided\" (present perfect tense), while in the output, it's \"decided\" (simple past tense). However, both tenses can be used to translate the French past tense \"d\u00e9cida\", depending on the context. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "Do you love her?", "ref": "either", "src": "Est-ce que tu l'aimes ?", "tgt": "Do you love him?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is a hallucination. The French input \"Est-ce que tu l'aimes ?\" translates to \"Do you love him?\" in English. However, the model incorrectly translated it to \"Do you love her?\" This is incorrect as the gender of the person being referred to has been changed from male to female. Therefore, the output is not accurate.", "predicted": "Hallucination"}, {"hyp": "I got the company.", "ref": "either", "src": "J'ai de la compagnie.", "tgt": "I've got company.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination. The translation provided by the model, \"I got the company,\" is not entirely incorrect but it's not the most accurate translation. The target translation \"I've got company\" is more accurate and natural in English. The model's output could be interpreted as the person acquiring a business, which is not the intended meaning of the original French sentence. However, it does not add or infer any information that wasn't present in the original input, so it cannot be classified as a hallucination.", "predicted": "Not Hallucination"}, {"hyp": "He's got several friends.", "ref": "either", "src": "Ann a plusieurs amis.", "tgt": "Ann has many friends.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input sentence is about \"Ann\", a female, but the output sentence refers to a male subject \"He\". The translation is incorrect because it changes the gender of the subject. The correct translation should be \"Ann has several friends.\"", "predicted": "Hallucination"}, {"hyp": "The captain orders the ship on board.", "ref": "either", "src": "Le capitaine donne l'ordre d'embarquer sur le navire.", "tgt": "The skipper is giving the order to board the ship.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is not a hallucination, but it is not entirely accurate. The input sentence in French says \"The captain gives the order to board the ship.\" The output, \"The captain orders the ship on board,\" is not a correct translation. The correct translation is provided in the target: \"The skipper is giving the order to board the ship.\" Therefore, while the output is not a hallucination as it does not introduce new or unrelated information, it is not an accurate translation of the input.", "predicted": "Not Hallucination"}, {"hyp": "Sami called 911.", "ref": "either", "src": "Sami a appel\u00e9 le 911.", "tgt": "Sami made a call to 911.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input \"Sami a appel\u00e9 le 911\" translates directly to \"Sami called 911\" in English. The output is correct and accurate, and it does not contain any information that cannot be reasonably inferred from the input. The target translation \"Sami made a call to 911\" is also correct, but it is a more verbose way of saying the same thing. The output provided by the model is more concise and natural.", "predicted": "Not Hallucination"}, {"hyp": "We love our school.", "ref": "either", "src": "Nous aimons notre \u00e9cole.", "tgt": "We like our school.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output uses the word \"love\" instead of \"like\" which is the direct translation of \"aimons\", it still conveys a similar meaning. In the context of translation, it is not uncommon for certain words to be translated in a way that slightly alters the intensity of the sentiment, but still maintains the overall message. Therefore, while the translation is not exact, it is not incorrect or off point.", "predicted": "Not Hallucination"}, {"hyp": "How'd you get \"pretty\"?", "ref": "either", "src": "Comment \u00e9pelles-tu \"pretty\" ?", "tgt": "How do you spell \"pretty\"?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input is asking how to spell the word \"pretty\" in French, but the output is asking how the word \"pretty\" was obtained. The output does not accurately translate the input, thus it is incorrect and off point.", "predicted": "Hallucination"}, {"hyp": "The old days will never come back.", "ref": "either", "src": "Les jours anciens ne reviendront jamais.", "tgt": "The old days have gone never to return.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output does not match the target exactly, it still accurately translates the meaning of the original French sentence. Both the target and output convey the same idea that the old days will not return. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "I bought three different varieties of flowers.", "ref": "either", "src": "J\u2019ai achet\u00e9 trois diff\u00e9rentes sortes de fleurs.", "tgt": "I bought three different kinds of flowers.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output does not match the target exactly, it is still a correct and accurate translation of the input. The words \"sortes\" and \"varieties\" are synonyms in this context, so the meaning of the sentence is preserved. Therefore, the output is not a hallucination, as it does not contain incorrect information or stray from the original input.", "predicted": "Not Hallucination"}, {"hyp": "It's my duty.", "ref": "either", "src": "C'est mon m\u00e9tier.", "tgt": "It's my job.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination. While the output does not match the target exactly, it is still a correct and reasonable translation of the input. In French, \"C'est mon m\u00e9tier\" can be translated as \"It's my job\" or \"It's my duty\". Both translations are accurate and convey the same general meaning. Therefore, the output is not a hallucination, but rather an alternative correct translation.", "predicted": "Not Hallucination"}, {"hyp": "I have nothing to do with it.", "ref": "either", "src": "J'en ai rien \u00e0 secouer.", "tgt": "I don't give a shit about it.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is not a hallucination. However, it is not entirely accurate. The French phrase \"J'en ai rien \u00e0 secouer\" is a colloquial expression that translates more closely to the target \"I don't give a shit about it.\" The output \"I have nothing to do with it\" is a more literal translation and while it conveys a similar sentiment of disinterest or disconnection, it does not fully capture the dismissive and somewhat vulgar tone of the original phrase. Therefore, while the output is not a hallucination, it is not a completely accurate translation.", "predicted": "Not Hallucination"}, {"hyp": "I've been confiscated.", "ref": "either", "src": "On m'a confisqu\u00e9 mon permis.", "tgt": "I've had my driving license confiscated.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The output \"I've been confiscated\" is incorrect and does not accurately translate the input \"On m'a confisqu\u00e9 mon permis.\" The correct translation is provided in the target \"I've had my driving license confiscated.\" The output misses the crucial information about the driving license being confiscated, which is present in the input.", "predicted": "Hallucination"}, {"hyp": "Stop turning.", "ref": "either", "src": "Arr\u00eate de tourner.", "tgt": "Stop spinning.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input \"Arr\u00eate de tourner\" is correctly translated to \"Stop turning\" in English. Although the target translation is \"Stop spinning\", both \"turning\" and \"spinning\" can be used interchangeably in this context, and thus the output is still accurate and correct.", "predicted": "Not Hallucination"}, {"hyp": "What kind of bread are you eating in general?", "ref": "either", "src": "Quel genre de pain est-ce que tu manges en g\u00e9n\u00e9ral ?", "tgt": "What kind of bread do you usually eat?", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output is not an exact match of the target, it still accurately translates the meaning of the original French sentence. The phrases \"do you usually eat\" and \"are you eating in general\" are semantically very similar, both referring to a habitual or regular action. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "The eagles are friends.", "ref": "either", "src": "Les araign\u00e9es sont mignonnes.", "tgt": "Spiders are cute.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input sentence in French, \"Les araign\u00e9es sont mignonnes,\" translates to \"Spiders are cute\" in English. However, the output provided by the model, \"The eagles are friends,\" is not a correct translation. It introduces new concepts (eagles and friends) that were not present in the original input, hence it is a hallucination.", "predicted": "Hallucination"}, {"hyp": "Farhat Mehenni's separatist group concluded a compromise with the radical Islamist group Rachad for the destabilization of Algeria. This led Algeria to officially consider the two groups as terrorist organizations.", "ref": "either", "src": "Le groupe s\u00e9paratiste de Ferhat Mehenni a conclu un compromis avec le groupe islamiste radical Rachad pour la d\u00e9stabilisation de l'Alg\u00e9rie. C'est ce qui a conduit l'Alg\u00e9rie \u00e0 officiellement consid\u00e9rer les deux groupes comme des organisations terroristes.", "tgt": "Ferhat Mehenni's separatist group cut a deal with the radical Islamist group Rachad to destabilize Algeria. That's what led Algeria to officially consider both groups as terrorist organizations.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. It accurately translates the input from French to English, maintaining the same meaning and context. The only minor difference is the use of the word \"compromise\" instead of \"deal\" in the translation, but both words convey the same meaning in this context. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "You certainly don't have your mother's good nature.", "ref": "either", "src": "Tu n'as certainement pas la bonne nature de ta m\u00e8re.", "tgt": "You definitely don't have the good nature of your mother.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output is not a word-for-word translation of the input, it accurately conveys the same meaning as the input and the target. The phrase \"You certainly don't have your mother's good nature\" is a valid translation of \"Tu n'as certainement pas la bonne nature de ta m\u00e8re.\" Therefore, the language model has performed the task correctly.", "predicted": "Not Hallucination"}, {"hyp": "Tom didn't hurry.", "ref": "either", "src": "Tom n'a pas hurl\u00e9.", "tgt": "Tom didn't scream.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The French sentence \"Tom n'a pas hurl\u00e9\" translates to \"Tom didn't scream\" in English. However, the model incorrectly translated it as \"Tom didn't hurry.\" Therefore, the output is not accurate and does not correctly represent the information from the input.", "predicted": "Hallucination"}, {"hyp": "Do you like tomatoes?", "ref": "either", "src": "Tom aime-t-il les tomates ?", "tgt": "Tom likes tomatoes?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input is in French and asks \"Does Tom like tomatoes?\" The target translation correctly reflects this. However, the output generated by the model incorrectly translates the sentence as \"Do you like tomatoes?\" The model has incorrectly replaced \"Tom\" with \"you\", thus changing the subject of the sentence. This is not a correct or accurate translation of the input.", "predicted": "Hallucination"}, {"hyp": "In this case we see the results all the time.", "ref": "either", "src": "Dans ce m\u00e9tier on voit tout de suite les r\u00e9sultats.", "tgt": "In this activity one immediately sees the result.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is not a hallucination. Although it does not match the target exactly, it still accurately conveys the main idea of the input. The input sentence in French translates to \"In this job, we immediately see the results.\" The output, \"In this case we see the results all the time,\" is a slightly different interpretation but it still maintains the core meaning of seeing results quickly or immediately in a certain situation or job. Therefore, it is not a hallucination as it does not introduce any new or unrelated information.", "predicted": "Not Hallucination"}, {"hyp": "I really think you should leave.", "ref": "either", "src": "Je pense vraiment que vous devriez partir.", "tgt": "I really think you should leave.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The input sentence is in French and the output is its correct translation in English. The model has accurately translated the sentence without adding, omitting, or distorting any information. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "Make him a horse!", "ref": "either", "src": "Fais-lui un c\u00e2lin !", "tgt": "Give her a hug.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input in French, \"Fais-lui un c\u00e2lin !\" translates to \"Give him/her a hug!\" in English. The output, \"Make him a horse!\" is not a correct translation of the input and introduces information (\"Make him a horse\") that cannot be inferred from the input. Therefore, it is incorrect and off point.", "predicted": "Hallucination"}, {"hyp": "Don't lend anyone else the book you borrowed.", "ref": "either", "src": "Ne pr\u00eate pas \u00e0 un autre le livre que tu as emprunt\u00e9.", "tgt": "Don't lend a borrowed book to another.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The translation provided by the language model is accurate and conveys the same meaning as the input. The input, in French, instructs not to lend a book that has been borrowed to someone else. The output accurately translates this instruction into English. Although the wording is slightly different from the target, the meaning remains the same, which is the primary goal of machine translation. Therefore, the output is correct and not a hallucination.", "predicted": "Not Hallucination"}, {"hyp": "I want to drink something free.", "ref": "either", "src": "Je veux boire quelque chose de frais.", "tgt": "I want something cold to drink.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The French phrase \"quelque chose de frais\" translates to \"something cold\" in English, not \"something free\". Therefore, the model's translation is incorrect and does not accurately reflect the information given in the input.", "predicted": "Hallucination"}, {"hyp": "Do you have a cryon?", "ref": "either", "src": "As-tu un crayon ?", "tgt": "Have you got a pencil?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is not a hallucination. The output is a correct translation of the input, but there is a minor spelling mistake. The word \"cryon\" should be \"pencil\". Despite this error, the overall meaning of the sentence is preserved and it is not introducing any new or unrelated information that cannot be inferred from the input. Therefore, it cannot be classified as a hallucination.", "predicted": "Not Hallucination"}, {"hyp": "I talked to other people in the same situation.", "ref": "either", "src": "J'ai discut\u00e9 avec d'autres personnes dans la m\u00eame situation.", "tgt": "I have talked with others in the same situation.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. Although the output does not match the target exactly, it still accurately translates the meaning of the original French sentence. The difference between \"I have talked\" and \"I talked\" is minimal and does not change the overall meaning. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "The nurse will check your arm within 2 days to see if there's any reaction.", "ref": "either", "src": "L'infirmier v\u00e9rifiera ton bras dans les 2 jours pour voir s'il y a une r\u00e9action.", "tgt": "The nurse will check your arm within 2 days to see if there is a reaction.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. It accurately translates the input from French to English. The slight difference between the target and the output (\"if there is a reaction\" vs \"if there's any reaction\") does not change the overall meaning of the sentence. Both versions correctly convey the information from the original French input.", "predicted": "Not Hallucination"}, {"hyp": "You're not missing anyone.", "ref": "either", "src": "Tu ne manques \u00e0 personne.", "tgt": "No one misses you.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output is a hallucination. The input sentence in French, \"Tu ne manques \u00e0 personne,\" translates to \"No one misses you\" in English. However, the model incorrectly translated it to \"You're not missing anyone.\" This is a clear case of hallucination as the output is not only incorrect but also conveys a different meaning than the original input.", "predicted": "Hallucination"}, {"hyp": "I've got the floor and the furniture.", "ref": "either", "src": "J'ai poli le plancher et les meubles.", "tgt": "I polished up the floor and furniture.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input sentence in French is \"J'ai poli le plancher et les meubles\" which translates to \"I polished the floor and the furniture\". However, the output provided by the language model is \"I've got the floor and the furniture\", which is not an accurate translation of the input. The model incorrectly translated \"poli\" (polished) as \"got\", thus providing information that cannot be reasonably inferred from the input.", "predicted": "Hallucination"}, {"hyp": "I can't do it alone.", "ref": "either", "src": "Je ne peux le faire seule. Il vous faut m'aider.", "tgt": "I can't do it alone. You have to help me.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.3333333333333333, "rationale": "The output is not a hallucination, but it is incomplete. The language model correctly translated the first sentence of the input, \"Je ne peux le faire seule,\" to \"I can't do it alone.\" However, it failed to translate the second sentence, \"Il vous faut m'aider,\" which should be \"You have to help me.\" Therefore, while the output is not a hallucination, it is not fully correct or accurate because it does not include the entire translation of the input.", "predicted": "Not Hallucination"}, {"hyp": "He lost what he received from his father.", "ref": "either", "src": "Il a perdu ce qu'il a re\u00e7u de son p\u00e8re.", "tgt": "He wasted that which he had received from his father.", "model": "", "task": "MT", "labels": ["Not Hallucination", "Not Hallucination", "Not Hallucination"], "label": "Not Hallucination", "p(Hallucination)": 0.0, "rationale": "The output is not a hallucination. The output accurately translates the input from French to English. The only difference between the target and the output is the use of the word \"wasted\" instead of \"lost\". However, both words can be used interchangeably in this context, and the meaning of the sentence remains the same. Therefore, the output is correct and accurate.", "predicted": "Not Hallucination"}, {"hyp": "We've discovered a lot of news.", "ref": "either", "src": "Nous avons d\u00e9couvert une grande nouveaut\u00e9.", "tgt": "We have discovered a great novelty.", "model": "", "task": "MT", "labels": ["Hallucination", "Not Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 0.6666666666666666, "rationale": "The output can be considered a hallucination. The original French sentence translates to \"We have discovered a great novelty.\" However, the language model translated it as \"We've discovered a lot of news.\" The output is incorrect because it changes the meaning of the original sentence. The term \"grande nouveaut\u00e9\" was inaccurately translated as \"a lot of news\" instead of \"a great novelty.\" Therefore, the output is not an accurate translation of the input.", "predicted": "Hallucination"}, {"hyp": "Why is everyone okay?", "ref": "either", "src": "Pourquoi est-ce que tout le monde rigole ?", "tgt": "Why is everyone laughing?", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The input sentence in French is asking \"Why is everyone laughing?\" but the model's translation asks \"Why is everyone okay?\" The model's output does not accurately translate the original input, introducing a concept (\"okay\") that was not present in the original sentence. Therefore, it can be considered a hallucination.", "predicted": "Hallucination"}, {"hyp": "No matter what you do to your guide.", "ref": "either", "src": "Chacun fait \u00e0 sa guise.", "tgt": "Each one does as he likes.", "model": "", "task": "MT", "labels": ["Hallucination", "Hallucination", "Hallucination"], "label": "Hallucination", "p(Hallucination)": 1.0, "rationale": "The output is a hallucination. The correct translation of the French sentence \"Chacun fait \u00e0 sa guise\" is \"Each one does as he likes\". The output \"No matter what you do to your guide\" is not an accurate translation of the input and introduces new information that is not present in the original sentence, such as the concept of a \"guide\". Therefore, the output is incorrect and off point.", "predicted": "Hallucination"}]