
# Conceptual Engineering Using Large Language Models

## Overview
In philosophy, *conceptual engineering* is ”the design, implementation, and evaluation of
concepts” [1]. There are a wide range of views as to how conceptual engineering is to be performed, and even about the meaning of the term *concept* itself, but in many instances it is clearly an activity where language processing is a significant element. In recent years, large language models
(LLMs) have emerged as a technology that promises to be of ”substantial value in the
scientific study of language learning and processing” [2]. The Python notebooks in this repository investigate the question of whether or not large language models can be used to support the process of conceptual engineering.

## References

[1] David J Chalmers. What is conceptual engineering and what should it be? Inquiry, pages 1–18, 2020.

[2] Kevin Scharp. Philosophy as the study of defective concepts. In Conceptual engineering and conceptual
ethics, pages 396–416. Oxford University Press, 2020.

[3] Herman Cappelen and David Plunkett. Introduction: A guided tour of conceptual engineering and
conceptual ethics. In Conceptual engineering and conceptual ethics, pages 1–26. Oxford University Press,
2020.

[4] Manuel Gustavo Isaac, Steffen Koch, and Ryan Nefdt. Conceptual engineering: A road map to practice.
Philosophy Compass, 17(10):e12879, 2022.

[5] Sigurd Jorem. Conceptual engineering and the implementation problem. Inquiry, 64(1-2):186–211, 2021.

[6] Jennifer Nado. Classification procedures as the targets of conceptual engineering. Philosophy and
Phenomenological Research, 2021.

[7] Sally Haslanger. Gender and race:(what) are they? (what) do we want them to be? Noûs, 34(1):31–55,
2000.

[8] Catarina Dutilh Novaes. Carnapian explication and ameliorative analysis: A systematic comparison.
Synthese, 197(3):1011–1034, 2020.

[9] André W Carus. Carnap and twentieth-century thought: Explication as enlightenment. Cambridge
University Press, 2007.

[10] Rudolf Carnap. Meaning and necessity: a study in semantics and modal logic, volume 30. University of
Chicago Press, 1988.

[11] Georg Brun. Explication as a method of conceptual re-engineering. Erkenntnis, 81(6):1211–1241, 2016.

[12] Liam Kofi Bright, Daniel Malinsky, and Morgan Thompson. Causally interpreting intersectionality
theory. Philosophy of Science, 83(1):60–81, 2016.

[13] Catarina Dutilh Novaes and Erich Reck. Carnapian explication, formalisms as cognitive tools, and the
paradox of adequate formalization. Synthese, 194:195–215, 2017.

[14] Catarina Dutilh Novaes. Formal languages in logic: A philosophical and cognitive analysis. Cambridge
University Press, 2012.

[15] OpenAI. ”OpenAI API Reference”. https://platform.openai.com/docs/api-reference, 2023. Accessed:
2023-02-09.

[16] Kyle Mahowald, Anna A Ivanova, Idan A Blank, Nancy Kanwisher, Joshua B Tenenbaum, and Evelina
Fedorenko. Dissociating language and thought in large language models: a cognitive perspective. arXiv
preprint arXiv:2301.06627, 2023.

[17] Murray Shanahan. Talking about large language models. arXiv preprint arXiv:2212.03551, 2022.

[18] Gati Aher, Rosa I Arriaga, and Adam Tauman Kalai. Using large language models to simulate multiple
humans. arXiv preprint arXiv:2208.10264, 2022.

[19] Marcel Binz and Eric Schulz. Using cognitive psychology to understand gpt-3. Proceedings of the National
Academy of Sciences, 120(6):e2218523120, 2023.

[20] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the dangers
of stochastic parrots: Can language models be too big? . In Proceedings of the 2021 ACM Conference
on Fairness, Accountability, and Transparency, pages 610–623, 2021.

[21] Harry G Frankfurt. On bullshit. Princeton University Press, 2009.

[22] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy
Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022.
[23] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train,
prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM
Computing Surveys, 55(9):1–35, 2023.

[24] Laria Reynolds and Kyle McDonell. Prompt programming for large language models: Beyond the
few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing
Systems, pages 1–7, 2021.

[25] Justin D Weisz, Michael Muller, Jessica He, and Stephanie Houde. Toward general design principles for
generative ai applications. arXiv preprint arXiv:2301.05578, 2023.

[26] Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and
Sebastian Riedel. Language models as knowledge bases? arXiv preprint arXiv:1909.01066, 2019.

[27] Badr AlKhamissi, Millicent Li, Asli Celikyilmaz, Mona Diab, and Marjan Ghazvininejad. A review on
language models as knowledge bases. arXiv preprint arXiv:2204.06031, 2022.

[28] Roi Cohen, Mor Geva, Jonathan Berant, and Amir Globerson. Crawling the internal knowledge-base of
language models. arXiv preprint arXiv:2301.12810, 2023.

[29] Richard Sutton. The bitter lesson. Incomplete Ideas (blog), 13(1), 2019.

[30] Herbert A Simon. The computer as a laboratory for epistemology. In Philosophy and the Computer,
pages 3–23. Routledge, 2019.

[31] Harry Halpin and Alexandre Monnin. The decentralization of knowledge: How carnap and heidegger
influenced the web. First Monday, 2016.

[32] Allen Newell. The knowledge level. Artificial intelligence, 18(1):87–127, 1982.
