{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conceptual_engineering_toolkit import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\"benchmarks/european/data.json\", \"concepts/european/oed_european.yaml\", \"gpt-4\")\n",
    "sample = experiment.sample(n=100)\n",
    "experiment.run(sample)\n",
    "experiment_file = experiment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\"benchmarks/european/data.json\", \"concepts/european/oed_european.yaml\", \"gpt-4\", use_description=False)\n",
    "experiment.run(sample)\n",
    "experiment_file = experiment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\"benchmarks/european/data.json\", \"concepts/european/oed_european.yaml\", \"gpt-3.5-turbo\")\n",
    "experiment.run(sample)\n",
    "experiment_file = experiment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\"benchmarks/european/data.json\", \"concepts/european/oed_european.yaml\", \"text-curie-001\")\n",
    "experiment.run(sample)\n",
    "experiment_file = experiment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference API: Input validation error: `inputs` must have less than 1024 tokens. Given: 1068",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m experiment \u001b[39m=\u001b[39m Experiment(\u001b[39m\"\u001b[39m\u001b[39mbenchmarks/european/data.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mconcepts/european/oed_european.yaml\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgoogle/flan-t5-xxl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m experiment\u001b[39m.\u001b[39;49mrun(sample)\n\u001b[1;32m      3\u001b[0m experiment_file \u001b[39m=\u001b[39m experiment\u001b[39m.\u001b[39msave()\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/conceptual_engineering_toolkit.py:259\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, sample):\n\u001b[1;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_description:\n\u001b[0;32m--> 259\u001b[0m         predictions \u001b[39m=\u001b[39m [ \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconcept\u001b[39m.\u001b[39;49mclassify(Entity(entity[\u001b[39m\"\u001b[39;49m\u001b[39m@id\u001b[39;49m\u001b[39m\"\u001b[39;49m], entity[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m], entity[\u001b[39m\"\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m\"\u001b[39;49m])) \u001b[39mfor\u001b[39;49;00m entity \u001b[39min\u001b[39;49;00m sample ]\n\u001b[1;32m    260\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m         predictions \u001b[39m=\u001b[39m [ \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcept\u001b[39m.\u001b[39mclassify(Entity(entity[\u001b[39m\"\u001b[39m\u001b[39m@id\u001b[39m\u001b[39m\"\u001b[39m], entity[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m])) \u001b[39mfor\u001b[39;00m entity \u001b[39min\u001b[39;00m sample ]\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/conceptual_engineering_toolkit.py:259\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, sample):\n\u001b[1;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_description:\n\u001b[0;32m--> 259\u001b[0m         predictions \u001b[39m=\u001b[39m [ \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconcept\u001b[39m.\u001b[39;49mclassify(Entity(entity[\u001b[39m\"\u001b[39;49m\u001b[39m@id\u001b[39;49m\u001b[39m\"\u001b[39;49m], entity[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m], entity[\u001b[39m\"\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m\"\u001b[39;49m])) \u001b[39mfor\u001b[39;00m entity \u001b[39min\u001b[39;00m sample ]\n\u001b[1;32m    260\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m         predictions \u001b[39m=\u001b[39m [ \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcept\u001b[39m.\u001b[39mclassify(Entity(entity[\u001b[39m\"\u001b[39m\u001b[39m@id\u001b[39m\u001b[39m\"\u001b[39m], entity[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m])) \u001b[39mfor\u001b[39;00m entity \u001b[39min\u001b[39;00m sample ]\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/conceptual_engineering_toolkit.py:113\u001b[0m, in \u001b[0;36mConcept.classify\u001b[0;34m(self, entity)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassify\u001b[39m(\u001b[39mself\u001b[39m, entity):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m    Determines whether or not an entity is in the extension of the concept.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m        Classification results based on the concept's definition.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_classify_chain(\n\u001b[1;32m    114\u001b[0m         {\n\u001b[1;32m    115\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel, \n\u001b[1;32m    116\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mdefinition\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefinition, \n\u001b[1;32m    117\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mentity\u001b[39;49m\u001b[39m\"\u001b[39;49m: entity\u001b[39m.\u001b[39;49mlabel,\n\u001b[1;32m    118\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m\"\u001b[39;49m: entity\u001b[39m.\u001b[39;49mdescription\n\u001b[1;32m    119\u001b[0m         }\n\u001b[1;32m    120\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/chains/base.py:258\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    259\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    260\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    261\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    262\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/chains/base.py:252\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    246\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    247\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    248\u001b[0m     inputs,\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    253\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    254\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/chains/sequential.py:105\u001b[0m, in \u001b[0;36mSequentialChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mfor\u001b[39;00m i, chain \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchains):\n\u001b[1;32m    104\u001b[0m     callbacks \u001b[39m=\u001b[39m _run_manager\u001b[39m.\u001b[39mget_child()\n\u001b[0;32m--> 105\u001b[0m     outputs \u001b[39m=\u001b[39m chain(known_values, return_only_outputs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m    106\u001b[0m     known_values\u001b[39m.\u001b[39mupdate(outputs)\n\u001b[1;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m {k: known_values[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_variables}\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/chains/base.py:258\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    259\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    260\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    261\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    262\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/chains/base.py:252\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    246\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    247\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    248\u001b[0m     inputs,\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    253\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    254\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/chains/llm.py:92\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     89\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     90\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     91\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 92\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/chains/llm.py:102\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    103\u001b[0m     prompts,\n\u001b[1;32m    104\u001b[0m     stop,\n\u001b[1;32m    105\u001b[0m     callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    106\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[1;32m    107\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/llms/base.py:455\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    448\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    449\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    453\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    454\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 455\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/llms/base.py:586\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         )\n\u001b[1;32m    580\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    581\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    582\u001b[0m             dumpd(\u001b[39mself\u001b[39m), [prompt], invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[1;32m    583\u001b[0m         )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    584\u001b[0m         \u001b[39mfor\u001b[39;00m callback_manager, prompt \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(callback_managers, prompts)\n\u001b[1;32m    585\u001b[0m     ]\n\u001b[0;32m--> 586\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    587\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    588\u001b[0m     )\n\u001b[1;32m    589\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    590\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/llms/base.py:492\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    491\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 492\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    493\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/llms/base.py:479\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    471\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    476\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    477\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 479\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    480\u001b[0m                 prompts,\n\u001b[1;32m    481\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    482\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    483\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    484\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    485\u001b[0m             )\n\u001b[1;32m    486\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    487\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    488\u001b[0m         )\n\u001b[1;32m    489\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    490\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/llms/base.py:965\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m    964\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    966\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    967\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    968\u001b[0m     )\n\u001b[1;32m    969\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m    970\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/Documents/GitHub/conceptual-engineering-using-llms/lib/python3.11/site-packages/langchain/llms/huggingface_hub.py:113\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient(inputs\u001b[39m=\u001b[39mprompt, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m response:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError raised by inference API: \u001b[39m\u001b[39m{\u001b[39;00mresponse[\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mtask \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    115\u001b[0m     \u001b[39m# Text generation return includes the starter text.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     text \u001b[39m=\u001b[39m response[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39mlen\u001b[39m(prompt) :]\n",
      "\u001b[0;31mValueError\u001b[0m: Error raised by inference API: Input validation error: `inputs` must have less than 1024 tokens. Given: 1068"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\"benchmarks/european/data.json\", \"concepts/european/oed_european.yaml\", \"google/flan-t5-xxl\")\n",
    "experiment.run(sample)\n",
    "experiment_file = experiment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\"benchmarks/european/data.json\", \"concepts/european/wordnet_european.yaml\", \"gpt-4\")\n",
    "experiment.run(sample)\n",
    "experiment_file = experiment.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\"benchmarks/european/data.json\", \"concepts/european/dictionary_dot_com_adj_2_european.yaml\", \"gpt-4\")\n",
    "experiment.run(sample)\n",
    "experiment_file = experiment.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptual-engineering-using-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
