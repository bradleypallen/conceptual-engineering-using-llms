{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, operator, requests, time, pycm, pandas as pd\n",
    "from langchain import HuggingFaceHub, OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from conceptual_engineering_toolkit import Concept, Entity\n",
    "from datetime import datetime\n",
    "from string import Template\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"caligraph_experiments\"\n",
    "\n",
    "SPARQL_ENDPOINT = \"http://caligraph.org/sparql\"\n",
    "\n",
    "QUERY_HEADERS = {\n",
    "    'User-Agent': 'ConceptualEngineeringAgent/0.2 (https://github.com/bradleypallen/conceptual-engineering-using-llms; b.p.allen@uva.nl)'\n",
    "}\n",
    "\n",
    "CLASS_QUERY_LIMIT = 250\n",
    "\n",
    "E_QUERY_LIMIT = 20\n",
    "\n",
    "MIN_INSTANCE_COUNT = 100\n",
    "\n",
    "CLASS_QUERY_TEMPLATE = Template(\"\"\"SELECT ?class ?label ?superClass (COUNT(?instance) AS ?instanceCount) \n",
    "WHERE {\n",
    "   ?class rdf:type owl:Class ;\n",
    "        rdfs:label ?label ;\n",
    "        rdfs:subClassOf ?superClass .\n",
    "   ?instance rdf:type ?class .\n",
    "}\n",
    "GROUP BY ?class ?label ?superClass\n",
    "HAVING (COUNT(?instance) > $minInstanceCount)\n",
    "LIMIT $limit\n",
    "\"\"\")\n",
    "\n",
    "POSITIVES_QUERY_TEMPLATE = Template(\"\"\"SELECT ?instance ?label\n",
    "WHERE {\n",
    "  ?class rdfs:subClassOf* <$class> .\n",
    "  ?instance rdf:type ?class ;\n",
    "      rdfs:label ?label .\n",
    "}\n",
    "LIMIT $limit\n",
    "\"\"\")\n",
    "\n",
    "NEGATIVES_QUERY_TEMPLATE = Template(\"\"\"SELECT ?instance ?label\n",
    "WHERE {\n",
    "  ?subclassOfSuperClass rdfs:subClassOf* <$superClass> .\n",
    "  ?instance rdf:type ?subclassOfSuperClass ;\n",
    "       rdfs:label ?label .\n",
    " \n",
    "  FILTER NOT EXISTS {\n",
    "    ?subclassOfClass rdfs:subClassOf* <$class> .\n",
    "    ?instance rdf:type ?subclassOfClass .\n",
    "  }\n",
    "}\n",
    "LIMIT $limit\n",
    "\"\"\")\n",
    "                                  \n",
    "CLASS_DEFINITION_FROM_LABEL_PROMPT_TEMPLATE = Template(\"\"\"Define the concept \"$label\". \n",
    "Work step by step and check your facts. State your definition in the manner of a dictionary.\n",
    "\"\"\")\n",
    "\n",
    "CLASS_DEFINITION_FROM_TURTLE_PROMPT_TEMPLATE = Template(\"\"\"Using the following set of RDF statements, \n",
    "define the concept \"$label\". Work set by step and check your facts. State your definition in the manner \n",
    "of a dictionary.\n",
    "                                                           \n",
    "Turtle: $turtle'\n",
    "\"\"\")\n",
    "\n",
    "INSTANCE_DESCRIPTION_PROMPT_TEMPLATE = Template(\"\"\"Summarize the following set of RDF statements \n",
    "describing the entity \"$label\". Work set by step and check your facts. State your summarization \n",
    "in the manner of the first paragraph of an encylopedia article on the topic.\n",
    "                                                   \n",
    "Turtle: $turtle'\n",
    "\"\"\")\n",
    "\n",
    "def classes_for_evaluation():\n",
    "    query = CLASS_QUERY_TEMPLATE.substitute({\"minInstanceCount\": MIN_INSTANCE_COUNT, \"limit\": CLASS_QUERY_LIMIT})\n",
    "    response = requests.get(SPARQL_ENDPOINT, params={'query' : query, 'format' : 'json'}, headers=QUERY_HEADERS)\n",
    "    response.raise_for_status()\n",
    "    return sorted([ \n",
    "            { \n",
    "                \"id\": candidate[\"class\"][\"value\"], \n",
    "                \"label\": candidate[\"label\"][\"value\"], \n",
    "                \"superClassId\": candidate[\"superClass\"][\"value\"], \n",
    "                \"instanceCount\": candidate[\"instanceCount\"][\"value\"] \n",
    "            } \n",
    "            for candidate in response.json()[\"results\"][\"bindings\"] \n",
    "        ], \n",
    "        key=operator.itemgetter(\"instanceCount\"), \n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "def positive_examples(cls):\n",
    "    query = POSITIVES_QUERY_TEMPLATE.substitute({\"class\": cls[\"id\"], \"limit\": E_QUERY_LIMIT})\n",
    "    response = requests.get(SPARQL_ENDPOINT, params={'query' : query, 'format' : 'json'}, headers=QUERY_HEADERS)\n",
    "    response.raise_for_status()\n",
    "    return [ \n",
    "        { \n",
    "            \"id\": instance[\"instance\"][\"value\"], \n",
    "            \"label\": instance[\"label\"][\"value\"] \n",
    "        } \n",
    "        for instance in response.json()[\"results\"][\"bindings\"] \n",
    "    ]\n",
    "\n",
    "def negative_examples(cls):\n",
    "    query = NEGATIVES_QUERY_TEMPLATE.substitute({\"class\": cls[\"id\"], \"superClass\": cls[\"superClassId\"], \"limit\": E_QUERY_LIMIT})\n",
    "    response = requests.get(SPARQL_ENDPOINT, params={'query' : query, 'format' : 'json'}, headers=QUERY_HEADERS)\n",
    "    response.raise_for_status()\n",
    "    return [ \n",
    "        { \n",
    "            \"id\": instance[\"instance\"][\"value\"], \n",
    "            \"label\": instance[\"label\"][\"value\"] \n",
    "        } \n",
    "        for instance in response.json()[\"results\"][\"bindings\"] \n",
    "    ]\n",
    "\n",
    "def turtle(id):\n",
    "    response = requests.get(SPARQL_ENDPOINT, params={'query' : f'DESCRIBE <{id}>', 'format' : 'text\\turtle'}, headers=QUERY_HEADERS)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "def class_definition_from_label(label):\n",
    "    return ChatOpenAI(model=\"gpt-4\").predict(CLASS_DEFINITION_FROM_LABEL_PROMPT_TEMPLATE.substitute({\"label\": label}))\n",
    "\n",
    "def class_definition_from_turtle(id, label):\n",
    "    return ChatOpenAI(model=\"gpt-4\").predict(CLASS_DEFINITION_FROM_TURTLE_PROMPT_TEMPLATE.substitute({\"label\": label, \"turtle\": turtle(id)}))\n",
    "\n",
    "def instance_description(id, label):\n",
    "    return ChatOpenAI(model=\"gpt-4\").predict(INSTANCE_DESCRIPTION_PROMPT_TEMPLATE.substitute({\"label\": label, \"turtle\": turtle(id)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(cls):\n",
    "    positives = positive_examples(cls)\n",
    "    negatives = negative_examples(cls)\n",
    "    concept = Concept(cls[\"id\"], cls[\"label\"], class_definition_from_label(cls[\"label\"]), \"gpt-4\", 0.1)\n",
    "    df_positives = pd.DataFrame.from_records(positives)\n",
    "    df_positives[\"actual\"] = \"positive\"\n",
    "    df_negatives = pd.DataFrame.from_records(negatives)\n",
    "    df_negatives[\"actual\"] = \"negative\"\n",
    "    df_data = pd.concat([df_positives, df_negatives], ignore_index=True, axis=0)\n",
    "    df_data[\"description\"] = df_data.apply(lambda ex: instance_description(ex[\"id\"], ex[\"label\"]), axis=1)\n",
    "    predictions = [ concept.classify(Entity(ex[\"id\"], ex[\"label\"], ex[\"description\"])) for ex in df_data.to_dict(\"records\") ]\n",
    "    df_predictions = pd.DataFrame(predictions, columns = [ 'predicted', 'rationale' ])\n",
    "    df_predictions[\"predicted\"] = df_predictions[\"predicted\"].str.lower()\n",
    "    df_results = pd.concat([df_data, df_predictions], axis=1)\n",
    "    cm = pycm.ConfusionMatrix(df_results[\"actual\"].tolist(), df_results[\"predicted\"].tolist(), digit=2, classes=[ 'positive', 'negative' ])\n",
    "    evaluation = { \"created\": datetime.now().isoformat(), \"concept\": concept.to_json(), \"data\": df_results.to_dict('records'), \"confusion_matrix\": cm.matrix, }\n",
    "    experiment_filename = f'{DIRECTORY}/{cls[\"label\"].replace(\" \",\"_\")}/{evaluation[\"concept\"][\"model_name\"]}_{evaluation[\"concept\"][\"label\"].replace(\" \",\"_\")}_{evaluation[\"created\"]}.json'\n",
    "    experiment_path = Path(experiment_filename)\n",
    "    experiment_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    json.dump(evaluation, open(experiment_filename, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = classes_for_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Autobiography ...\n",
      "Evaluating Newspaper in New South Wales ...\n",
      "Evaluating Player of American football from Alabama ...\n",
      "Evaluating PlayStation VR game ...\n"
     ]
    }
   ],
   "source": [
    "for cls in candidates[1:20]:\n",
    "    time.sleep(60)\n",
    "    print(\"Evaluating\", cls[\"label\"], \"...\")\n",
    "    evaluate(cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptual-engineering-using-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
